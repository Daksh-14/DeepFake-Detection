{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyGg4bRe4v2+f2R+3HynKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daksh-14/DeepFake-Detection/blob/main/DeepFake_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9Lt5g6h6NnL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
        "from torchvision import transforms, models\n",
        "from torch import nn, optim\n",
        "from PIL import Image\n",
        "import random"
      ],
      "metadata": {
        "id": "TFBdrxAe6QzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the folder containing video files in your Google Drive\n",
        "video_folder_path = '/content/drive/MyDrive/Celeb-DF-v2.zip (Unzipped Files)/Celeb-synthesis'\n",
        "\n",
        "# Output folder for extracted frames\n",
        "output_frames_path = '/content/drive/MyDrive/Single_Extracted/Celeb-synthesis'\n",
        "os.makedirs(output_frames_path, exist_ok=True)\n",
        "\n",
        "# Number of frames to extract from each video\n",
        "num_frames_to_extract = 1\n",
        "\n",
        "# Iterate through all video files in the folder\n",
        "for video_file in os.listdir(video_folder_path):\n",
        "    if video_file.endswith(('.mp4', '.avi', '.mov')):  # Add other video formats if needed\n",
        "        video_path = os.path.join(video_folder_path, video_file)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        frame_count = 0\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        step = max(1, total_frames // num_frames_to_extract)\n",
        "\n",
        "        success, frame = cap.read()\n",
        "        while success and frame_count < num_frames_to_extract:\n",
        "            # Save frame as an image file\n",
        "            frame_filename = f\"{os.path.splitext(video_file)[0]}_frame{frame_count}.jpg\"\n",
        "            cv2.imwrite(os.path.join(output_frames_path, frame_filename), frame)\n",
        "\n",
        "            # Move to the next frame based on the step\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, step * (frame_count + 1))\n",
        "            frame_count += 1\n",
        "            success, frame = cap.read()\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"Extracted {frame_count} frames from {video_file}\")\n",
        "\n",
        "print(\"Frame extraction completed.\")"
      ],
      "metadata": {
        "id": "C9Vp9pIF6TRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Custom Dataset class to load frames\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.frames = [os.path.join(folder_path, frame) for frame in os.listdir(folder_path) if frame.endswith(\".jpg\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.frames[idx]\n",
        "        image = Image.open(img_path)\n",
        "        label = 1 if 'real' in img_path else 0  # Label as 1 for real, 0 for fake\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "hSXk621p6Vg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def oversample_dataset(real_dataset, fake_dataset):\n",
        "    # Calculate the number of samples needed to balance the dataset\n",
        "    real_count = len(real_dataset)\n",
        "    fake_count = len(fake_dataset)\n",
        "\n",
        "    # Create a list to hold the oversampled real images\n",
        "    oversampled_real_frames = []\n",
        "\n",
        "    # Add real images to the list until we reach the count of fake images\n",
        "    while len(oversampled_real_frames) < fake_count:\n",
        "        oversampled_real_frames.extend(real_dataset.frames)\n",
        "\n",
        "    # Randomly shuffle the oversampled frames and trim to the exact number of fake images needed\n",
        "    random.shuffle(oversampled_real_frames)\n",
        "    oversampled_real_frames = oversampled_real_frames[:fake_count]\n",
        "\n",
        "    # Create a new dataset with the oversampled real frames and original fake frames\n",
        "    combined_frames = oversampled_real_frames + fake_dataset.frames\n",
        "\n",
        "    # Create labels for the combined dataset (1 for real, 0 for fake)\n",
        "    combined_labels = [1] * len(oversampled_real_frames) + [0] * len(fake_dataset.frames)\n",
        "\n",
        "    return combined_frames, combined_labels\n",
        "\n",
        "# Data transforms (e.g., resizing and normalization)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load datasets for real and fake frames\n",
        "real_dataset = FrameDataset(folder_path=\"/content/drive/MyDrive/Colab Notebooks/Single_Extracted/Celeb-real\", transform=transform)\n",
        "fake_dataset = FrameDataset(folder_path=\"/content/drive/MyDrive/Colab Notebooks/Single_Extracted/Celeb-synthesis\", transform=transform)\n",
        "\n",
        "# Perform oversampling on the real dataset to match the size of the fake dataset\n",
        "combined_frames, combined_labels = oversample_dataset(real_dataset, fake_dataset)"
      ],
      "metadata": {
        "id": "GhQAEctE6YMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataset class to hold the combined data\n",
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, frames, labels, transform=None):\n",
        "        self.frames = frames\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.frames[idx]\n",
        "        image = Image.open(img_path)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Create a new combined dataset with oversampling applied\n",
        "combined_dataset = CombinedDataset(combined_frames, combined_labels, transform=transform)\n",
        "\n",
        "# Dataset splitting: 70% training, 15% validation, 15% testing\n",
        "total_length = len(combined_dataset)\n",
        "train_len = int(0.7 * total_length)\n",
        "val_len = int(0.15 * total_length)\n",
        "test_len = total_length - train_len - val_len\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(combined_dataset, [train_len, val_len, test_len])\n",
        "\n",
        "# Create DataLoaders for training, validation, and testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False,num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,num_workers=2)"
      ],
      "metadata": {
        "id": "RSfKxpVg6bJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture with shared backbone and separate branches (same as before)\n",
        "class DeepFakeDetector(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super(DeepFakeDetector, self).__init__()\n",
        "\n",
        "        resnet = models.resnet50(pretrained=pretrained)\n",
        "        self.shared_backbone = nn.Sequential(*(list(resnet.children())[:-2]))\n",
        "\n",
        "        # Eye Detection Branch\n",
        "        self.eye_conv = nn.Sequential(\n",
        "            nn.Conv2d(2048, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.eye_fc = nn.Linear(512 * 3 * 3, 256)\n",
        "        self.eye_classifier = nn.Linear(256, 2)\n",
        "\n",
        "        # Nose Detection Branch\n",
        "        self.nose_conv = nn.Sequential(\n",
        "            nn.Conv2d(2048, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.nose_fc = nn.Linear(512 * 3 * 3, 256)\n",
        "        self.nose_classifier = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.shared_backbone(x)\n",
        "        eye_features = self.eye_conv(features)\n",
        "        eye_features = eye_features.view(eye_features.size(0), -1)\n",
        "        eye_output = self.eye_classifier(self.eye_fc(eye_features))\n",
        "        nose_features = self.nose_conv(features)\n",
        "        nose_features = nose_features.view(nose_features.size(0), -1)\n",
        "        nose_output = self.nose_classifier(self.nose_fc(nose_features))\n",
        "\n",
        "        final_output = (eye_output + nose_output) / 2\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "hRocw7yX6dk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def train_model(model, optimizer, criterion, num_epochs=2, save_path=\"model_checkpoint.pth\"):\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Training phase\n",
        "        for batch in train_loader:\n",
        "            inputs, labels = batch\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            del inputs, labels, outputs, loss\n",
        "\n",
        "        running_loss /= len(train_loader)\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_batch in val_loader:\n",
        "                inputs_val, labels_val = val_batch\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    inputs_val, labels_val = inputs_val.cuda(), labels_val.cuda()\n",
        "\n",
        "                outputs_val = model(inputs_val)\n",
        "                loss_val = criterion(outputs_val, labels_val)\n",
        "                val_loss += loss_val.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save model checkpoint after evaluation\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': val_loss,\n",
        "        }\n",
        "        torch.save(checkpoint, save_path)\n",
        "        print(f\"Model saved at epoch {epoch+1}\")\n",
        "\n",
        "# Assuming DeepFakeDetector is the model class\n",
        "model = DeepFakeDetector(pretrained=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "train_model(model=model, optimizer=optimizer, criterion=criterion, num_epochs=20, save_path=\"/content/drive/MyDrive/Colab Notebooks/deepfake_detector_checkpoint.pth\")"
      ],
      "metadata": {
        "id": "qhpc8LLw6gMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_checkpoint(model, optimizer, checkpoint_path):\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    val_loss = checkpoint['loss']\n",
        "\n",
        "    print(f\"Checkpoint loaded. Resuming from epoch {epoch} with validation loss {val_loss:.4f}\")\n",
        "    print(f\"Model state dict keys: {model.state_dict().keys()}\")\n",
        "\n",
        "    return model, optimizer, epoch, val_loss\n",
        "\n",
        "model, optimizer, start_epoch, best_val_loss = load_model_checkpoint(model, optimizer, checkpoint_path)"
      ],
      "metadata": {
        "id": "ul0v0M3r6jUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_model_with_timing(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    total_time = 0.0\n",
        "    total_images = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            inputs, labels = batch\n",
        "            batch_size = inputs.size(0)\n",
        "            total_images += batch_size\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            # Measure the time taken for each batch prediction\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Update total time\n",
        "            total_time += (end_time - start_time)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    # Calculate average time per batch and per image\n",
        "    avg_time_per_batch = total_time / len(data_loader)\n",
        "    avg_time_per_image = total_time / total_images\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels), np.array(all_probs), total_time, avg_time_per_batch, avg_time_per_image\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix'):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Actual Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc_curve(y_true, y_scores):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_precision_recall_curve(y_true, y_scores):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(recall, precision, color='b', lw=2)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.show()\n",
        "\n",
        "# Get predictions, ground truth, and timing information\n",
        "preds, labels, probs, total_time, avg_time_per_batch, avg_time_per_image = evaluate_model_with_timing(model, test_loader)\n",
        "\n",
        "# Accuracy, Precision, Recall, F1-Score\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "precision = precision_score(labels, preds, average='weighted')\n",
        "recall = recall_score(labels, preds, average='weighted')\n",
        "f1 = f1_score(labels, preds, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Print timing information\n",
        "print(f\"Total time taken for predictions: {total_time:.4f} seconds\")\n",
        "print(f\"Average time per batch: {avg_time_per_batch:.4f} seconds\")\n",
        "print(f\"Average time per image: {avg_time_per_image:.6f} seconds\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plot_confusion_matrix(cm, classes=['Fake', 'Real'])\n",
        "\n",
        "# ROC and Precision-Recall curves (for binary classification)\n",
        "if len(np.unique(labels)) == 2:  # Check if it's binary classification\n",
        "    y_scores = probs[:, 1]  # Get probabilities for class 1\n",
        "    plot_roc_curve(labels, y_scores)\n",
        "    plot_precision_recall_curve(labels, y_scores)\n",
        "else:\n",
        "    print(\"ROC and Precision-Recall curves are only plotted for binary classification.\")"
      ],
      "metadata": {
        "id": "Jb754q8B6oZy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}